{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2e47927-86b9-4a42-9f06-4198d8e0e402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCIP version 10.0.0 [precision: 8 byte] [memory: block] [mode: optimized] [LP solver: SoPlex 8.0.0] [GitHash: 0c80fdd8e9]\n",
      "Copyright (c) 2002-2025 Zuse Institute Berlin (ZIB)\n",
      "\n",
      "External libraries: \n",
      "  SoPlex 8.0.0         Linear programming solver developed at Zuse Institute Berlin (soplex.zib.de) [GitHash: 2207cfb2]\n",
      "  CppAD 20180000.0     Algorithmic Differentiation of C++ algorithms developed by B. Bell (github.com/coin-or/CppAD)\n",
      "  ZLIB 1.3.1           General purpose compression library by J. Gailly and M. Adler (zlib.net)\n",
      "  MPFR 4.2.2           GNU Multiple Precision Floating-Point Reliable Library (mpfr.org)\n",
      "  Boost 1.83.0         Boost C++ Libraries (boost.org)\n",
      "  TinyCThread 1.2      small portable implementation of the C11 threads API (tinycthread.github.io)\n",
      "  GMP 6.3.0            GNU Multiple Precision Arithmetic Library developed by T. Granlund (gmplib.org)\n",
      "  ZIMPL 3.7.0          Zuse Institute Mathematical Programming Language developed by T. Koch (zimpl.zib.de)\n",
      "  AMPL/MP 4.0.3        AMPL .nl file reader library (github.com/ampl/mp)\n",
      "  PaPILO 3.0.0         parallel presolve for integer and linear optimization (github.com/scipopt/papilo) (built with TBB) [GitHash: 4cbdc327]\n",
      "  Nauty 2.8.8          Computing Graph Automorphism Groups by Brendan D. McKay (users.cecs.anu.edu.au/~bdm/nauty)\n",
      "  sassy 2.0            Symmetry preprocessor by Markus Anders (github.com/markusa4/sassy)\n",
      "  Ipopt 3.14.19        Interior Point Optimizer developed by A. Waechter et.al. (github.com/coin-or/Ipopt)\n",
      "\n",
      "reading user parameter file </tmp/ddf2ecf9cce84f1a88e56b439e1822ae-pulp.set>\n",
      "\n",
      "\n",
      "read problem </tmp/ddf2ecf9cce84f1a88e56b439e1822ae-pulp.lp>\n",
      "============\n",
      "\n",
      "original problem has 67880 variables (67880 bin, 0 int, 0 cont) and 229028 constraints\n",
      "\n",
      "presolving:\n",
      "(round 1, fast)       2820 del vars, 2820 del conss, 0 add conss, 2820 chg bounds, 0 chg sides, 0 chg coeffs, 0 upgd conss, 0 impls, 169482 clqs, 0 implints\n",
      "   (0.9s) running MILP presolver\n",
      "   (20.2s) MILP presolver (12 rounds): 5572 aggregations, 306 fixings, 0 bound changes\n",
      "(round 2, medium)     8698 del vars, 2820 del conss, 0 add conss, 2820 chg bounds, 0 chg sides, 0 chg coeffs, 0 upgd conss, 0 impls, 157790 clqs, 0 implints\n",
      "(round 3, fast)       8698 del vars, 20084 del conss, 0 add conss, 2820 chg bounds, 0 chg sides, 0 chg coeffs, 0 upgd conss, 0 impls, 157790 clqs, 0 implints\n",
      "(round 4, exhaustive) 8698 del vars, 20269 del conss, 0 add conss, 2820 chg bounds, 0 chg sides, 0 chg coeffs, 0 upgd conss, 0 impls, 157790 clqs, 0 implints\n",
      "(round 5, exhaustive) 8698 del vars, 20269 del conss, 0 add conss, 2820 chg bounds, 0 chg sides, 0 chg coeffs, 208759 upgd conss, 0 impls, 157790 clqs, 0 implints\n",
      "(round 6, exhaustive) 8698 del vars, 172753 del conss, 50828 add conss, 2820 chg bounds, 0 chg sides, 0 chg coeffs, 208759 upgd conss, 0 impls, 157790 clqs, 0 implints\n",
      "   (24.2s) symmetry computation started: requiring (bin +, int +, cont +), (fixed: bin -, int -, cont -)\n",
      "   (24.4s) symmetry computation finished: 12 generators found (max: 1500, log10 of symmetry group size: 7.46) (symcode time: 0.08)\n",
      "dynamic symmetry handling statistics:\n",
      "   orbitopal reduction:       no components\n",
      "   orbital reduction:          1 components of sizes 78\n",
      "   lexicographic reduction:   78 permutations with support sizes 460, 460, 460, 5616, 5616, 5616, 5616, 5616, 5616, 5616, 5616, 5616, 920, 920, 6032, 6032, 6032, 6032, 6032, 6032, 6032, 6032, 6032, 920, 6032, 6032, 6032, 6032, 6032, 6032, 6032, 6032, 6032, 6032, 6032, 6032, 6032, 6032, 6032, 6032, 6032, 6032, 5616, 11232, 11232, 11232, 11232, 11232, 11232, 11232, 5616, 11232, 11232, 11232, 11232, 11232, 11232, 5616, 11232, 11232, 11232, 11232, 11232, 5616, 11232, 11232, 11232, 11232, 5616, 11232, 11232, 11232, 5616, 11232, 11232, 5616, 11232, 5616\n",
      "handled 1 out of 1 symmetry components\n",
      "presolving (7 rounds: 7 fast, 5 medium, 4 exhaustive):\n",
      " 8723 deleted vars, 172753 deleted constraints, 50828 added constraints, 2820 tightened bounds, 0 added holes, 0 changed sides, 0 changed coefficients\n",
      " 0 implications, 164602 cliques, 0 implied integral variables (0 bin, 0 int, 0 cont)\n",
      "presolved problem has 59157 variables (59157 bin, 0 int, 0 cont) and 107103 constraints\n",
      "     20 constraints of type <knapsack>\n",
      "  56134 constraints of type <setppc>\n",
      "  50828 constraints of type <and>\n",
      "    121 constraints of type <logicor>\n",
      "transformed objective value is always integral (scale: 1)\n",
      "Presolving Time: 24.35\n",
      "\n",
      " time | node  | left  |LP iter|LP it/n|mem/heur|mdpt |vars |cons |rows |cuts |sepa|confs|strbr|  dualbound   | primalbound  |  gap   | compl. \n",
      "p27.7s|     1 |     0 |    17 |     - |   locks|   0 |  59k| 107k| 157k|   0 |  0 |   0 |   0 | 0.000000e+00 | 5.132550e+11 |    Inf | unknown\n",
      "i29.9s|     1 |     0 |   118 |     - |  oneopt|   0 |  59k| 107k| 157k|   0 |  0 | 235 |   0 | 0.000000e+00 | 1.926456e+11 |    Inf | unknown\n",
      " 31.1s|     1 |     0 |  1936 |     - |  1060M |   0 |  59k| 107k| 157k|   0 |  0 | 235 |   0 | 0.000000e+00 | 1.926456e+11 |    Inf | unknown\n",
      " 52.7s|     1 |     0 |  2231 |     - |  1116M |   0 |  59k| 107k| 157k|  44 |  1 | 291 |   0 | 0.000000e+00 | 1.926456e+11 |    Inf | unknown\n",
      " 60.0s|     1 |     0 |  2231 |     - |  1127M |   0 |  59k| 107k| 157k|  87 |  2 | 292 |   0 | 0.000000e+00 | 1.926456e+11 |    Inf | unknown\n",
      "(node 1) LP solver hit time limit in LP 4 -- using pseudo solution instead\n",
      "\n",
      "SCIP Status        : solving was interrupted [time limit reached]\n",
      "Solving Time (sec) : 60.01\n",
      "Solving Nodes      : 1\n",
      "Primal Bound       : +1.92645572126000e+11 (2 solutions)\n",
      "Dual Bound         : +0.00000000000000e+00\n",
      "Gap                : infinite\n",
      "\n",
      "\n",
      "written solution information to file </tmp/ddf2ecf9cce84f1a88e56b439e1822ae-pulp.sol>\n",
      "\n",
      "\n",
      "status: 1, Optimal\n",
      "objective: 192645572126.0\n"
     ]
    }
   ],
   "source": [
    "from pulp import LpMinimize, LpProblem, LpStatus, LpVariable, SCIP_PY, SCIP\n",
    "import pandas as pd\n",
    "\n",
    "# Parameters used for optimization \n",
    "number_of_bronze_dps = 20\n",
    "max_bronze_dp_size = 5\n",
    "max_optimization_execution_time = 60 #12*3600\n",
    "\n",
    "# Read and setup initial values\n",
    "dependencies = pd.read_csv('data/gold_dp_table_dependencies.csv')\n",
    "table_names = list(dependencies['table_name'])\n",
    "gold_dp_names = dependencies.columns[2:].to_list()\n",
    "gold_dp_indices = range(len(gold_dp_names))\n",
    "bronze_dp_indices = range(number_of_bronze_dps)\n",
    "num_rows_per_table = dict(zip(dependencies['table_name'], dependencies['num_rows']))\n",
    "required_tables_per_gold_dp = {g : set(dependencies[dependencies[g]]['table_name']) for g in gold_dp_names}\n",
    "\n",
    "# Create the model\n",
    "model = LpProblem(name=\"optimise-deps\", sense=LpMinimize)\n",
    "\n",
    "# Variables expressing whether gold_dp i requires bronze_dp j\n",
    "gb_tuples = [(g,b) for g in gold_dp_indices for b in bronze_dp_indices]\n",
    "gb_vars = LpVariable.dicts(\"gold-bronze-deps\", gb_tuples, cat=\"Binary\")\n",
    "\n",
    "# Variables expressing whether gold_dp i requires bronze_dp j\n",
    "tb_tuples = [(t,b) for t in table_names for b in bronze_dp_indices]\n",
    "tb_vars = LpVariable.dicts(\"table-in-bronze_rels\", tb_tuples, cat=\"Binary\")\n",
    "\n",
    "# Variables expressing whether gold_dp i requires table j\n",
    "gt_tuples = [(g,t) for g in gold_dp_indices for t in table_names]\n",
    "gt_vars = LpVariable.dicts(\"gold-table-deps\", gt_tuples, cat=\"Binary\")\n",
    "\n",
    "# Helper variables expressing whether gold_dp i obtains table j through bronze_dp k\n",
    "h_gbt_tuples = [(g,b,t) for g in gold_dp_indices for b in bronze_dp_indices for t in table_names]\n",
    "h_gbt_vars = LpVariable.dicts(\"helper-vars-table-via-bronze-in-gold\", h_gbt_tuples, cat=\"Binary\")\n",
    "\n",
    "# Helper variables expressing whether gold_dp i obtains table j\n",
    "h_gt_tuples = [(g,t) for g in gold_dp_indices for t in table_names]\n",
    "h_gt_vars = LpVariable.dicts(\"helper-vars-gold-contains-table\", h_gt_tuples, cat=\"Binary\")\n",
    "\n",
    "# Setup helper variables\n",
    "for gold_dp in gold_dp_indices:\n",
    "        for table in table_names:\n",
    "            for bronze_dp in bronze_dp_indices:\n",
    "                model += h_gbt_vars[gold_dp, bronze_dp, table] <= gb_vars[gold_dp, bronze_dp]\n",
    "                model += h_gbt_vars[gold_dp, bronze_dp, table] <= tb_vars[table, bronze_dp]\n",
    "                model += h_gbt_vars[gold_dp, bronze_dp, table] >= gb_vars[gold_dp, bronze_dp] + tb_vars[table, bronze_dp] - 1\n",
    "                model += h_gt_vars[gold_dp,table] >= h_gbt_vars[gold_dp, bronze_dp, table]\n",
    "\n",
    "# Setup gt_vars by according to dependencies in input file\n",
    "for gold_dp in gold_dp_indices:\n",
    "    req_tables = list(dependencies[dependencies[gold_dp_names[gold_dp]]]['table_name'])\n",
    "    for table in table_names:\n",
    "        if table in req_tables:\n",
    "            model += gt_vars[gold_dp, table] == 1\n",
    "        else:\n",
    "            model += gt_vars[gold_dp, table] == 0\n",
    "\n",
    "# Setup requirement for maximum size of bronze dps\n",
    "for bronze_dp in bronze_dp_indices:\n",
    "    expr = 0\n",
    "    for table in table_names:\n",
    "        expr += tb_vars[table, bronze_dp]\n",
    "    model += expr <= max_bronze_dp_size\n",
    "\n",
    "# Setup requirement for gold dps to obtain all their dependencies\n",
    "for gold_dp in gold_dp_indices:\n",
    "        for table in table_names:\n",
    "            expr = 0\n",
    "            for bronze_dp in bronze_dp_indices:\n",
    "                expr += h_gbt_vars[gold_dp, bronze_dp, table]\n",
    "            if table in required_tables_per_gold_dp[gold_dp_names[gold_dp]]:\n",
    "                model += expr >= 1\n",
    "\n",
    "# Setup requirement to have each table in a single bronze dp only\n",
    "for table in table_names:\n",
    "    expr = 0\n",
    "    for bronze_dp in bronze_dp_indices:\n",
    "        expr += tb_vars[table, bronze_dp]\n",
    "    model += expr <= 1\n",
    "\n",
    "# Setup goal to minimize unnecessarily loaded table rows\n",
    "optimization_expr_per_gold_dp = {}\n",
    "optimization_expr = 0\n",
    "for gold_dp in gold_dp_indices:\n",
    "        optimization_expr_per_gold_dp[gold_dp] = 0\n",
    "        for table in table_names:\n",
    "            optimization_expr_per_gold_dp[gold_dp] += -gt_vars[gold_dp, table]*num_rows_per_table[table]\n",
    "            optimization_expr_per_gold_dp[gold_dp] += h_gt_vars[gold_dp, table]*num_rows_per_table[table]\n",
    "        optimization_expr += optimization_expr_per_gold_dp[gold_dp]\n",
    "\n",
    "model += optimization_expr\n",
    "\n",
    "# Solve the problem\n",
    "solver = SCIP(timeLimit=max_optimization_execution_time)\n",
    "status = model.solve(solver)\n",
    "\n",
    "# Print result\n",
    "print(f\"status: {model.status}, {LpStatus[model.status]}\")\n",
    "print(f\"objective: {model.objective.value()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ea5855-afff-4b6d-91c4-ac082ebb4e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes to visualize optimal relations\n",
    "\n",
    "gold_bronze_dependencies = pd.DataFrame(index=bronze_dp_indices, columns=gold_dp_indices)\n",
    "for gold_dp in gold_dp_indices:\n",
    "    for bronze_dp in bronze_dp_indices:\n",
    "        if gb_vars[gold_dp, bronze_dp].varValue >= 1:\n",
    "            gold_bronze_dependencies.at[bronze_dp, gold_dp] = True\n",
    "        else:\n",
    "            gold_bronze_dependencies.at[bronze_dp, gold_dp] = False\n",
    "\n",
    "bronze_table_relations = pd.DataFrame(index=table_names, columns=bronze_dp_indices)\n",
    "for bronze_dp in bronze_dp_indices:\n",
    "    for table in table_names:\n",
    "        if tb_vars[table, bronze_dp].varValue >= 1:\n",
    "            bronze_table_relations.at[table, bronze_dp] = True\n",
    "        else:\n",
    "            bronze_table_relations.at[table, bronze_dp] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a174138-ea3c-4925-88b3-916193ff9517",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate current dependencies of gold products\n",
    "\n",
    "data_rows = []\n",
    "\n",
    "for gold_dp in gold_dp_indices:\n",
    "    bronze_dps_per_gold_dp = list(gold_bronze_dependencies[gold_bronze_dependencies[gold_dp]].index)\n",
    "    available_tables_per_gold_dp = list(bronze_table_relations[bronze_table_relations[bronze_dps_per_gold_dp].any(axis=1)].index)\n",
    "    \n",
    "    req_tables = dependencies[dependencies[gold_dp_names[gold_dp]]]\n",
    "    available_tables = dependencies[dependencies['table_name'].isin(available_tables_per_gold_dp)]\n",
    "    req_rows = req_tables['num_rows'].sum()\n",
    "    available_rows = available_tables['num_rows'].sum()\n",
    "    req_table_count = len(req_tables)\n",
    "    available_table_count = len(available_tables)\n",
    "    \n",
    "\n",
    "    data_rows.append({\n",
    "        'gold_product': gold_dp_names[gold_dp], \n",
    "        'Number of required tables': req_table_count, \n",
    "        'Number of available tables': available_table_count,\n",
    "        'Number of required data rows': req_rows, \n",
    "        'Number of available data rows': available_rows,\n",
    "        'Ratio of required data over available data': 0 if available_rows == 0 else req_rows/available_rows,\n",
    "    })\n",
    "\n",
    "gold_dependencies_analysis = pd.DataFrame(data_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e838876-73c9-4d33-abc6-9fcc1e8977cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Summary to Excel\n",
    "\n",
    "with pd.ExcelWriter('data/optimization_summary.xlsx', engine='openpyxl') as writer:\n",
    "    dependencies.to_excel(writer, sheet_name='Dependencies Gold DP to Tables', index=False)\n",
    "    gold_bronze_dependencies.to_excel(writer, sheet_name='Mapping Bronze DP to Gold DP')\n",
    "    bronze_table_relations.to_excel(writer, sheet_name='Mapping Table to Bronze DP')\n",
    "    gold_dependencies_analysis.to_excel(writer, sheet_name='Validation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lp_dp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
